{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data, mnist.target.astype('int32'),\n",
    "                           random_state=42)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "mnist_X, mnist_y = mnist_X[:1000], mnist_y[:1000]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=43)\n",
    "\n",
    "# one-of-k表現にする。\n",
    "train_y = np.eye(10)[train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "        self.W = np.random.uniform(low= -0.08, high= 0.08, size=(in_dim, out_dim)).astype(\"float32\")\n",
    "        self.b = np.zeros(out_dim).astype(\"float32\")\n",
    "        self.function = function\n",
    "        self.deriv_function = deriv_function\n",
    "        self.u = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def f_prop(self, x):\n",
    "        self.u = np.dot(x, self.W) + self.b\n",
    "        self.z = self.function(self.u)\n",
    "        return self.z\n",
    "    \n",
    "    def b_prop(self, delta, W):\n",
    "        self.delta = self.deriv_function(self.u)*np.dot(delta, W.T)\n",
    "        return self.delta\n",
    "    \n",
    "def f_props(layers, x):\n",
    "    z = x\n",
    "    for layer in layers:\n",
    "        z = layer.f_prop(z)\n",
    "    return z\n",
    "\n",
    "def b_props(layers, delta):\n",
    "    for i, layer in enumerate(layers[::-1]):\n",
    "        if i == 0:\n",
    "            layer.delta = delta\n",
    "        else:\n",
    "            delta = layer.b_prop(delta, _W)\n",
    "        _W = layer.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [Layer(784, 100, sigmoid, deriv_sigmoid),\n",
    "          Layer(100, 10, sigmoid, deriv_sigmoid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E ( {\\bf \\theta} ) =  -\\sum^N_{n=1} \\left[ t_n \\log y ({\\bf x}_n ; {\\bf \\theta}) + (1 - t_n) \\log \\{ 1 - y ({\\bf x}_n ; {\\bf \\theta}) \\}\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, t, eps=1.0):\n",
    "    y = f_props(layers, X)\n",
    "    delta = y - t\n",
    "    b_props(layers, delta)\n",
    "\n",
    "    z = X\n",
    "    for i, layer in enumerate(layers):\n",
    "        dW = np.dot(z.T, layer.delta)\n",
    "        db = np.dot(np.ones(len(z)), layer.delta)\n",
    "        layer.W = layer.W - eps*dW\n",
    "        layer.b = layer.b - eps*db\n",
    "        z = layer.z\n",
    "\n",
    "def test(X, t):\n",
    "    y = f_props(layers, X)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/Users/arakawariku/.pyenv/versions/miniconda3-3.19.0/envs/ml_env/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "\n",
      " 20%|██        | 2/10 [00:00<00:01,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=10)\n",
    "for epoch in range(10):\n",
    "    pbar.update(1)\n",
    "    for x, y in zip(train_X, train_y):\n",
    "        train(x[np.newaxis, :], y[np.newaxis, :])    \n",
    "    pred_y = test(test_X, test_y)\n",
    "    pred_y = [np.argmax(y) for y in pred_y]\n",
    "    print(accuracy_score(pred_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
